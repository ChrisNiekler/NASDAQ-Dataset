{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentQs_Demo",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVfzb/0QwySu2DkkXjlo0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChristophRaab/NASDAQ-Dataset/blob/master/SentQs_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu-yX3Bg1ypP"
      },
      "source": [
        "<h1>SentQS Demo\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "This files shows how to download the SentQs dataset and train an 1D-CNN on it \r\n",
        "More information about the dataset can be found at:\r\n",
        "\r\n",
        "https://github.com/ChristophRaab/NASDAQ-Dataset\r\n",
        "\r\n",
        "Author: Christoph Raab "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vniUbsTW2Zm2"
      },
      "source": [
        "<h2> Import modules and load data into program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1Ldq_su1V4S"
      },
      "source": [
        "from tensorflow.keras.preprocessing import sequence\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\r\n",
        "from tensorflow.keras.layers import Embedding\r\n",
        "from tensorflow.keras.layers import LSTM\r\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D,Conv2D, BatchNormalization\r\n",
        "from tensorflow.keras.datasets import imdb\r\n",
        "import requests\r\n",
        "import sys\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "import numpy as np\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6jZAeVvDJiM",
        "outputId": "9601da3b-1462-4aa9-987f-bd1fa35503f1"
      },
      "source": [
        "# Download data\r\n",
        "!wget --no-check-certificate https://cloud.fhws.de/index.php/s/4sJ69ocZW8epAke/download -O sentqs_dataset.npz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-10 08:51:10--  https://cloud.fhws.de/index.php/s/4sJ69ocZW8epAke/download\n",
            "Resolving cloud.fhws.de (cloud.fhws.de)... 193.174.83.161\n",
            "Connecting to cloud.fhws.de (cloud.fhws.de)|193.174.83.161|:443... connected.\n",
            "WARNING: cannot verify cloud.fhws.de's certificate, issued by ‘CN=DFN-Verein Global Issuing CA,OU=DFN-PKI,O=Verein zur Foerderung eines Deutschen Forschungsnetzes e. V.,C=DE’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98939622 (94M) [application/octet-stream]\n",
            "Saving to: ‘sentqs_dataset.npz’\n",
            "\n",
            "sentqs_dataset.npz  100%[===================>]  94.36M  5.34MB/s    in 17s     \n",
            "\n",
            "2020-12-10 08:51:29 (5.40 MB/s) - ‘sentqs_dataset.npz’ saved [98939622/98939622]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZfHG-5A2qDN"
      },
      "source": [
        "#Load data into program\r\n",
        "file_name = \"sentqs_dataset.npz\"\r\n",
        "data = np.load(file_name,allow_pickle=True)\r\n",
        "Xs = data[\"arr_0\"]\r\n",
        "Ys = data[\"arr_1\"]\r\n",
        "Xt = data[\"arr_2\"]\r\n",
        "Yt = data[\"arr_3\"]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRGQ0-4C1FdZ"
      },
      "source": [
        "<h2> Preprocess (Only one call per runtime)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV0NTFum1BSk",
        "outputId": "a2c273fb-bb72-4e22-c609-b56cb2c49c25"
      },
      "source": [
        "# Standardize  data\r\n",
        "Xs = (Xs - Xs.mean(0)) / Xs.std(0)\r\n",
        "Xt = (Xt - Xt.mean(0)) / Xt.std(0)\r\n",
        "\r\n",
        "# Make data compatible with conv1d layers\r\n",
        "Xs = np.expand_dims(Xs, 2)\r\n",
        "Xt = np.expand_dims(Xt, 2)\r\n",
        "\r\n",
        "# Make labels comaptible with categorical cross-entropy \r\n",
        "Ys = to_categorical(Ys,3)\r\n",
        "Yt = to_categorical(Yt,3)\r\n",
        "\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21395, 200, 1)\n",
            "(21395, 3)\n",
            "(40134, 200, 1)\n",
            "(40134, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2RWCQnd1O_E"
      },
      "source": [
        "<h2> Model paramters and defintion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZLOXS0d2yJA"
      },
      "source": [
        "# Model Parameters\r\n",
        "# Convolution\r\n",
        "kernel_size = 5\r\n",
        "filters = 64\r\n",
        "pool_size = 4\r\n",
        "# LSTM\r\n",
        "lstm_output_size = 70\r\n",
        "# Training\r\n",
        "batch_size = 128\r\n",
        "epochs = 30\r\n",
        "num_classes = Ys.shape[1]\r\n",
        "\r\n",
        "# Define and compile CNN-LSTM-Network\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv1D(filters,\r\n",
        "                 kernel_size,\r\n",
        "                 padding='valid',\r\n",
        "                 activation='relu',\r\n",
        "                 strides=1))\r\n",
        "model.add(MaxPooling1D(pool_size=pool_size))\r\n",
        "model.add(LSTM(lstm_output_size))\r\n",
        "model.add(Dense(100))\r\n",
        "model.add(Dense(35))\r\n",
        "model.add(Dense(num_classes))\r\n",
        "model.add(Activation('softmax'))\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer='adam',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIrPUxfP1c7d"
      },
      "source": [
        "<h2>  Train and Evaluate Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccmRoOGgGEjw",
        "outputId": "ccac0967-ba98-48f2-ce07-4d4edd659881"
      },
      "source": [
        "# Test if data has valid shapes\r\n",
        "assert Xs.shape == (21395,200,1)\r\n",
        "assert Ys.shape == (21395,3)\r\n",
        "assert Xt.shape == (40134,200,1)\r\n",
        "assert Yt.shape == (40134,3)\r\n",
        "model.fit(Xs, Ys,\r\n",
        "          batch_size=batch_size,\r\n",
        "          epochs=epochs,\r\n",
        "          validation_data=(Xt, Yt))\r\n",
        "score, acc = model.evaluate(Xt, Yt, batch_size=batch_size)\r\n",
        "model.summary()\r\n",
        "print(\"Evaluated CNN-LSTM Neural Network\")\r\n",
        "print('Test score:', score)\r\n",
        "print('Test accuracy:', acc)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "168/168 [==============================] - 2s 15ms/step - loss: 0.6525 - accuracy: 0.7645 - val_loss: 1.7290 - val_accuracy: 0.1315\n",
            "Epoch 2/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.6323 - accuracy: 0.7690 - val_loss: 1.9935 - val_accuracy: 0.1117\n",
            "Epoch 3/30\n",
            "168/168 [==============================] - 2s 12ms/step - loss: 0.6254 - accuracy: 0.7712 - val_loss: 1.8529 - val_accuracy: 0.1113\n",
            "Epoch 4/30\n",
            "168/168 [==============================] - 2s 12ms/step - loss: 0.6192 - accuracy: 0.7731 - val_loss: 1.9587 - val_accuracy: 0.1117\n",
            "Epoch 5/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.6164 - accuracy: 0.7731 - val_loss: 1.9151 - val_accuracy: 0.1117\n",
            "Epoch 6/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.6143 - accuracy: 0.7736 - val_loss: 2.0243 - val_accuracy: 0.1117\n",
            "Epoch 7/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.6135 - accuracy: 0.7736 - val_loss: 1.8653 - val_accuracy: 0.1116\n",
            "Epoch 8/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.6114 - accuracy: 0.7735 - val_loss: 1.8975 - val_accuracy: 0.1118\n",
            "Epoch 9/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.6074 - accuracy: 0.7738 - val_loss: 1.8214 - val_accuracy: 0.1117\n",
            "Epoch 10/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.6064 - accuracy: 0.7742 - val_loss: 1.9660 - val_accuracy: 0.1117\n",
            "Epoch 11/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.6049 - accuracy: 0.7745 - val_loss: 2.0129 - val_accuracy: 0.1117\n",
            "Epoch 12/30\n",
            "168/168 [==============================] - 2s 12ms/step - loss: 0.6020 - accuracy: 0.7749 - val_loss: 1.7550 - val_accuracy: 0.1135\n",
            "Epoch 13/30\n",
            "168/168 [==============================] - 2s 12ms/step - loss: 0.6006 - accuracy: 0.7750 - val_loss: 2.0159 - val_accuracy: 0.1120\n",
            "Epoch 14/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.5995 - accuracy: 0.7753 - val_loss: 1.8402 - val_accuracy: 0.1121\n",
            "Epoch 15/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.5973 - accuracy: 0.7746 - val_loss: 1.9046 - val_accuracy: 0.1161\n",
            "Epoch 16/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.5948 - accuracy: 0.7753 - val_loss: 2.0345 - val_accuracy: 0.1184\n",
            "Epoch 17/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.5917 - accuracy: 0.7761 - val_loss: 1.9053 - val_accuracy: 0.1213\n",
            "Epoch 18/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.5891 - accuracy: 0.7766 - val_loss: 2.1641 - val_accuracy: 0.1188\n",
            "Epoch 19/30\n",
            "168/168 [==============================] - 2s 12ms/step - loss: 0.5900 - accuracy: 0.7767 - val_loss: 1.9916 - val_accuracy: 0.1235\n",
            "Epoch 20/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.5846 - accuracy: 0.7771 - val_loss: 1.9577 - val_accuracy: 0.1217\n",
            "Epoch 21/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.5830 - accuracy: 0.7785 - val_loss: 2.0996 - val_accuracy: 0.1286\n",
            "Epoch 22/30\n",
            "168/168 [==============================] - 2s 11ms/step - loss: 0.5806 - accuracy: 0.7786 - val_loss: 1.9500 - val_accuracy: 0.1217\n",
            "Epoch 23/30\n",
            " 84/168 [==============>...............] - ETA: 0s - loss: 0.5768 - accuracy: 0.7812"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}